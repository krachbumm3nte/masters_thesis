
\chapter{Discussion}


\section{Contribution}




\subsection{criteria for biological plausibility}

In which we discuss, to what extent the network conforms to the criteria for biologically plausible learning rules
introduced by \cite{Whittington2017}:
\begin{enumerate}
      \item Local computation. A neuron performs computation only on the basis
            of the inputs it receives from other neurons weighted by the strengths
            of its synaptic connections.
      \item  Local plasticity. The amount of synaptic weight modification is dependent on only the activity of the two
            neurons the synapse connects (and possibly a neuromodulator).
      \item  Minimal external control. The neurons perform the computation autonomously with as little external control
            routing information in different ways at different times as possible.
      \item   Plausible architecture. The connectivity patterns in the model should
            be consistent with basic constraints of connectivity in neocortex.
\end{enumerate}




One of the predictions about cortical activity made by predictive coding is an increased network activity in response to
senesory input violating the generative model. This behaviour is to be expected, as local prediction errors in these
networks are encoded in the activation of error neurons. A diverse set of studies has since independently reported
behaviour consistent with this hypothesis in primate cortical neurons (see \citep{bastos2012canonical}[Table 1] for an
extensive review). This property is also listed in Table \ref{tab-wb-models} in support of the predictive coding
network, but not the dendritic error model. As this is an experimentally testable hypothesis, a simple experiment was
conducted. A network with two hidden layers (dims=[9,30,10,3]) was presented with stimuli from the Bars-dataset. The
number of spikes were recorded for three paradigms: Fully random weights, self-predicting weights, and post-training
weights from a previous experiment. Results are shown in Figure \ref{fig-stimulus-response}




\section{Should it be considered pre-training?}

\todo{someone said this network needs pre-training and that made me sad :(}





\section{Limitations}


\subsection{Computational efficiency}

Computational efficiency has been a limiting factor for the kinds of tasks the dendritic error network
could be trained on. This includes the work done in this thesis, as (once the implementation was ready) both time and
computing resources were in limited supply.

In its current state, the implementation must be considered inefficient in comparison to other approximations of
Backprop. This limitation existed in the original implementation and was largely dealt with through steady-state
approximations and the addition of Latent equilibrium. The SNN implementation in the present work reintroduces this
issue, and regrettably exacerbates the problem considerably. To a degree, decreased speed is an inadvertable price to be
paid for a more exact modelling of neuronal processes. There is a high computational cost attached to more complex
neuron dynamics, plasticity rules, network structures and so forth. In short, any attempt at introducing more features
of biological brains into an existing model must be expected to decrease performance. Given the level of
abstraction in the present model paired with its poor speed, this perspective is slightly concerning. Therefore, before
developing this model further, it should be rigorously optimized.

Some initial directions for this are provided by the benchmarks performed in this study. The spike-based plasticity rule
appears to be highly costly, and should be optimized or approximated. One possible optimization was already provided by
\citep{Stapmanns2021}. In the paper, a third update variant for the dendritic plasticity rule is discussed. Instead of a
strictly event-based or time-based update rule, a hybrid variant called "Event-based update with compression" is
discussed. In this method, whenever a spike is received by the postsynaptic neuron, all incoming synapses are updated
with the updated dendritic potentials. This variant trades an increased number of synapse updates for the removal of
redundant computations. For this reason, it proved particularly advantageous for networks in which neurons had a large
number of incoming synapses, and average spike frequencies were low. Pyramidal neurons are often innervated by thousands
of neurons \citeme and reportedly have much lower spike frequencies than modeled here. Therefore, this alternative
integration scheme can be expected to perform well for further experiments in this direction. Regrettably, it was not
available in time for this thesis, so this remains speculative for now.

Another alternative is, to approximate the full plasticity rule with the instantaneous error at the time of a spike.
This would eliminate the requirement for both frequent updates, as well as for storing a history of dendritic error.
Thus, a network employing this simplified plasticity rule would be much less computationally costly. As shown in Fig.
\ref{fig-error-comp-le}, error terms in LE networks relax after only a few simulation steps. Therefore, under the
condition that input remains static throughout, this crude approximation is expected to perform fairly well. \newline

\noindent The neuron model should likewise be investigated for potential improvements in terms of efficiency. Modeling
interneurons without an apical compartment might yield some improvements (although initials experiments have dampened
expectations for this). It is also possible, that the network does not require integration timesteps as low as $0.1ms$,
which has not been investigated yet. \newline

\subsubsection*{Neuromorphic hardware}

A prospect which likely would vastly improve simulation speed is a full re-implementation of the neuron model on
neuromorphic hardware. This model fits the self-described niche of such systems almost perfectly; It employs strictly
local plasticity rules, its nodes use leaky membrane dynamics and communicate through binary spikes. By a rough
estimation, even the first generation of Intel's Loihi chips \citep{davies2018loihi} should be capable of simulating
this neuron model. The chip is capable of modelling multiple dendritic trees per neuron, and the learning engine appears
capable of communicating the dendritic error to all synapses. It is however possible that the learning rule would need
to be approximated somewhat for Loihi 1, this requires further investigation. The publicly available information about
the follow-up chip Loihi 2 \citep{Davies2021} is still somewhat sparse, but it claims to support a much more diverse set
of learning rules. Thus, this is a promising direction for further development of this network. Of course, Loihi is only
one of many neuromorphic systems \citep{rajendran2019low}. Another very promising system is \textit{BrainScaleS-2},
which trades off some speed for substantially increased complexity in the neuron models. It appears to be spearheading
the field with regard to simulating segregated dendrites \citep{Kaiser2022}, which might make it even more appealing
for a re-implementation.

Neuromorphic systems are unified in promising to vastly improve computational speed and energy efficience of large
spiking neural networks. Furthermore, the vast majority of them provides a basis for leaky-, spiking-, and
multi-compartment neuron models as core design pillars. Due to these properties, neuromorphic hardware is a good fit and
a promising future direction for the dendritic error model.






\subsection{In search of plausible spike frequencies}
\todo{expand}

\subsection*{Network}

Oversized networks have a higher tendency of failing on some tasks (results not shown). This issue is not consistent,
but plagued some of my experiments with no satisfactory explanation yet found.


When injecting large currents (i.e. in func approx experiments), the network kinda shits itself. Somewhat
expected, somewhat annoying




\section{Future directions}

\subsection{Additional Backprop concerns}


from \citep{Marblestone2016} on one-shot learning

Additionally, the nervous system may have a way of quickly
storing and replaying sequences of events. This would allow
the brain to move an item from episodic memory into a long-
term memory stored in the weights of a cortical network (Ji and
Wilson, 2007), by replaying the memory over and over. This
solution effectively uses many iterations of weight updating to
fully learn a single item, even if one has only been exposed to
it once. Alternatively, the brain could rapidly store an episodic
memory and then retrieve it later without the need to perform
slow gradient updates, which has proven to be useful for
fast reinforcement learning in scenarios with limited available
data (Blundell et al., 2016)


Where do targets come from? \cite{Bengio2015}


\section{Correspondence of the final model to cortical circuitry}

Cortical neurons depend on neuromodulation too \cite{Roelfsema2018}

Completely unclear whether cortical circuits perform supervised learning \citep{magee2020synaptic}


This would probs be super efficient on neuromorphics!

I am not going to try plasticity with spike-spike or spike-rate dendritic errors

Training on ImageNet

Making this shit faster

BPTT/time-continuous inputs


The dendritic error rule at the core of Urbanczik-Senn looks absurdly similar to superspike \citep{Zenke2018}.
Someone should look into that!

Different configurations for which synapses are plastic should be elaborated on.


\subsection{Neuron model}


The neuron models employed in the network can be improved in several ways. Note, that this perspective is not made with
learning performance in mind, but rather with increased correspondence to the cortical circuitry.



Two properties that are part of most spiking neuron models, but have not been investigated here, are membrane reset and
refractory periods. The neuron model contains a mechanism for refractoriness after a spike, yet no experiments regarding
the impact of this feature on learning have yet been performed. As a natural extension of this, resetting the membrane
potential after eliciting a spike could likewise improve biological plausibility with simple changes to the model. These
two changes together would change the spike generation process to that of a stochastic LIF neuron. These neurons have
previously performed well for modelling sensory representations in the cortex \citep{Pillow2008}. Another neuron
property considered in that study is \textit{spike-frequency-adaptation}. Neurons with this mechanism increase their
threshold potential in response to previous activity. Such adaptability has been observed in $\tilde 20 \% $ of neurons
in the mouse visual cortex \citep{allen2018}, and has been shown to lead to significant performance increases in
recurrent SNN \citep{bellec2018long,bellec2020solution}. A neuron model capable of this has already been implemented in
NEST, so extending the present model in this regard should be feasible. These three changes together would vastly
improve correspondence of the neuron model to physiological insights. If successful, learning with such a model would
lend further support to the model's claim of biological plausibility.






pyr and intn are wayy to similar

reward-modulated urbanczik-senn plasticity?

wtf is shunting inhibition?

Consider neurogenesis deeper. Any network that is plausible must be able to develop in a plausible fashion. Investigating
how the cortex develops might hold insights into plausible connectivity schemes. This does not necessarily compete or
conflict with looking at connectivity of developed brains


\subsubsection{improve prospective activity with regard to spike creation}

le does a lot, particularly at hidden layers. Yet response time under spiking paradigms is still
lackluster. In particular, prospective activation does next to nothing for these very low input time
constants. SNN performs best when $\tau_x$ is greater than $\Delta_t$ by roughly x10.





\subsection{Improving efficiency}




\section{Conclusion}
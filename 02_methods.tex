\chapter{Methods}

\section{The dendritic error model}

This section will go into detail about the dendritic error network \citep{sacramento2018dendritic}. The model contains a
somewhat complex and strongly recurrent connectivity, which poses one of the major criticisms aimed at it
\citep{whittington2019theories}. Much like traditional machine learning networks, it can be functionally separated into
layers. Yet in this particular model, input- hidden- and output layers are quite distinct in both neuron populations and
connectivity.


\subsection{Network architecture}

\begin{figure}[h!]
  \centering
  \begin{minipage}{0.5\textwidth}
    \centering
    \includegraphics[width=0.9\textwidth]{network_a}
  \end{minipage}\hfill
  \begin{minipage}{0.4\textwidth}
    \centering
    \includegraphics[width=0.9\textwidth]{network_b}
  \end{minipage}
  \caption[Structure of the dendritic error network]{Structure of the dendritic error network, from \citep{Haider2021}.
    \textbf{a:} pyramidal- (red) and interneurons (blue) in a network of three layers. Note the fact that the number
    interneurons in a layer is equal to the number of pyramidal neurons in the subsequent layer\protect\footnotemark.
    \textbf{b:} connectivity within the highlighted section. Feedback pyramidal-to-interneuron connections (displayed
    with rectangular synapse) transmit pyramidal somatic potential directly and connect to a single interneuron. This
    enables these interneurons to learn to match their corresponding next-layer pyramidal neurons. All other synapses
    (circles) transmit the neuron's somatic activation $\phi (u^{som})$ and fully connect their origin and target
    populations.}
  \label{fig-network}
\end{figure}

\footnotetext{{Note that the input layer is displayed as having interneurons here. This appears to be a mistake in the
      Figure. Within the implementation, interneurons are only modelled in hidden layers.}}

The basic connectivity scheme of the model is shown in Fig. \ref{fig-network}. Neurons at the input layer receive no
feedback signals and serve primarily to apply a temporal low-pass filter to the stimulus which is injected into their
membrane.  Hidden layers consist of a pyramidal- and an interneuron population, which are fully connected to each other
reciprocally. Both types of neurons are represented by multi-compartment models with leaky membrane dynamics.
Interneurons contain one somatic and one dendritic compartment, while pyramidal neurons are modeled with both a basal
and an apical dendrite.  Feedforward connections between layers are facilitated by all-to-all connections between their
respective pyramidal neurons and innervate basal compartments. Feedback connections from superficial pyramidal neurons,
as well as lateral interneuron connections arrive at the apical compartments of pyramidal neurons. Thus, a hidden layer
pyramidal neuron forms two reciprocal loops, one with all interneurons in the same layer, and one with all pyramidal
neurons in the next layer.

all interneurons further receive feedback information from superficial pyramidal neurons. These feedback connections are
unique within this model, as they connect one pyramidal neuron to exactly one interneuron. Instead of transmitting a
neuronal activation as all other synapses do, these connections relay somatic voltage directly. This one-to-one
connectivity puts a strict constraint on the number of interneurons in a hidden layer, as it must be equal to the number
of subsequent pyramidal neurons. These pairs of inter- and pyramidal neurons will henceforth be called \textit{sister
neurons}. The top-down signal serves to \textit{nudge} interneuron somatic activation towards that of their pyramidal
sisters. The purpose of an interneuron in this architecture is then to predict the activity of its sister neuron. Any
failure to do so results in layer-specific errors which in turn are the driving force of learning in the employed
plasticity rule, but more on this later.

Output layers have no interneurons, and are usually modeled as pyramidal neurons without an apical compartment. During
learning, the target for the network's activation is injected into their somatic compartment. Through the feedback
connections, it can propagate through the entire network. To understand this mechanism, neuron models and plasticity
rules require some elaboration.


\subsection{Neuron models}\label{sec-neurons}



The network contains two types of multi-compartment neurons; pyramidal neurons with three compartments each, and
interneurons with two compartments each. They integrate synaptic inputs into dendritic potentials, which in turn leak
into the soma with specific conductances. Note that vector notation will be used throughout this section, and $u_l^P$
and $u_l^I$ denote the column vectors of pyramidal- and interneuron somatic voltages at layer $l$, respectively.
Synaptic weights $W$ are likewise assumed matrices of size $n \times m$, which are the number of output and input
neurons of the connected populations respectively. The activation (or rate) $r_l^P$ of pyramidal neurons is thus given
by applying the neuronal transfer function $\phi$ to their somatic potentials:
\begin{align}
  r_l^P   & = \phi(u_l^P)                                                                      \\
  \phi(x) & = \begin{cases}
                0                                   & \textrm{if } \ x < -\epsilon               \\
                \gamma \ log(1+e^{\beta(x-\theta)}) & \textrm{if } \ -\epsilon \leq x < \epsilon \\
                \gamma \ x                          & \textrm{otherwise}
              \end{cases}
\end{align}

where $\phi$ acts component wise on $u$ and can be interpreted as a smoothed variant of ReLu (sometimes called
\textit{Softplus}) with scaling factors $\gamma=1$, $\beta=1$, $\theta=0$. Splitting the computation with the threshold
parameter $\epsilon=15$ does not alter its output much, but instead serves to prevent overflow errors for large absolute
values of $x$.  Where applicable, pyramidal- and interneurons will be differentiated with superscripts $P$ and $I$
respectively. The basal and apical dendrites of pyramidal neurons are denoted with superscripts $bas$ and $api$
respectively, while interneuron dendrites are simply denoted $dend$.  The derivative somatic membrane potentials of
layer $l$ pyramidal neurons is given by:

\begin{align}
  C_m \dot{u}_l^P & = - g_l u_l^{P} + g^{bas} v_l^{bas} + g^{api} v_l^{api} \label{eq-pyr-dynamics-rate}
\end{align}

where $g_l$ is the somatic leakage conductance, and $C_m$ is the somatic membrane capacitance which will be assumed to
be $1$ from here on out. $v_l^{bas}$ and $v_l^{api}$ are the membrane potentials of basal and apical dendrites
respectively, and $g^{bas}$ and $g^{api}$ their corresponding coupling conductances.  Dendritic compartments in this
model have no persistence between simulation steps. Thus, they are defined at every timestep $t$ through incoming weight
matrices and presynaptic activities:

\begin{align}
  v_l^{bas}(t) & = W_l^{up} \ \phi(u_{l-1}^P(t)) \label{eq-v-bas-rate}                                     \\
  v_l^{api}(t) & =  W_l^{pi} \ \phi(u_l^I(t)) \ + \  W_l^{down} \ \phi(u_{l+1}^P(t)) \label{eq-v-api-rate}
\end{align}

the nomenclature for weight matrices conforms to \citep{Haider2021}, where they are indexed by the layer in which their
target neurons lie, and belong to one of four populations: Feedforward and feedback pyramidal-to-pyramidal connections
arriving at layer $l$ are denoted $W_l^{up}$ and $W_l^{down}$ respectively. Lateral pyramidal-to-interneuron connections
are denoted with $W_l^{ip}$ and their corresponding feedback connections with $W_l^{pi}$.

Interneurons are modeled largely identically. Top-down nudging signals from their sister neurons is injected directly
into the soma:

\begin{align}
  C_m \dot{u}_l^I & = - g_l u_l^{I} + g^{dend} v_l^{dend} + i^{nudge, I}\label{eq-intn-dynamics} \\
  i^{nudge, I}    & = g^{nudge, I} u_{l+1}^P                                                     \\
  v_l^{dend}      & = W_l^{ip} \ \phi(u_{l}^P)
\end{align}

where $ g^{nudge, I}$ is the interneuron nudging conductance, and $u_{l+1}^P$ is the somatic voltage of pyramidal
neurons in the next layer.  Pyramidal neurons in the output layer $N$ effectively behave like interneurons, as they
receive no input to their apical compartment. Instead, the target  activation $u^{tgt}$ is injected into their soma:

\begin{align}
  C_m \dot{u}_N^P & = - g_l u_N^{P} + g^{bas} v_N^{bas} + i^{nudge, tgt} \\
  i^{nudge, tgt}  & = g^{nudge, tgt} u^{tgt}
\end{align}


these neuron dynamics correspond closely to those described in \citep{urbanczik2014learning}, including the extension to
more than two compartments which was proposed in the original paper. It should be noted however, that they are
simplified in some ways. These simplifications enabled the authors to prove analytically that this model approximates
Backprop. Yet, they do come at the cost of omitting neuroscientific insights from the model, which will be discussed
later.

\section{Urbanczik-Senn plasticity}\label{sec-urb-senn-plast}

The synapses in the network are all modulated according to variations of the "Urbanczik-Senn" plasticity rule
\citep{urbanczik2014learning}, which will be discussed in this section. Note that as for the neuron model, the dendritic
error model slightly simplifies some equations of the plasticity rule from its original implementation.

\subsection{Derivation}

The plasticity rule is defined for postsynaptic neurons which have one somatic and at least one dendritic compartment,
to the latter of which synapses of this type can connect. Functionally, synaptic weights are changed in such a way, as
to minimize discrepancies between somatic and dendritic potentials. This discrepancy is called the \textit{dendritic
prediction error}, and is defined as the difference between the somatic firing rate and a hypothetical dendritic
activation. The change in weight for a synapse from neuron $j$ to the basal compartment of a pyramidal neuron $i$ is
given by:

\begin{align}
  \dot{w}_{ij}    & = \eta \ ( \phi(u_i^{som}) - \phi(\hat{v}_i^{bas}) ) \ \phi(u_j^{som})^T \\
  \hat{v}_i^{bas} & = \alpha \  v_i^{bas}
\end{align}

with learning rate $\eta$, and $u^T$ denoting the transposition of the vector $u$. The dendritic prediction
$\hat{v}_i^{bas}$ is a scaled version of the dendritic potential by the constant factor $\alpha$, which is calculated
from coupling and leakage conductances. As an example, basal dendrites of pyramidal neurons in
\citep{sacramento2018dendritic} are attenuated by $\alpha = \frac{g^{bas}}{g_l + g^{bas} + g^{api}}$. A key property of
this value for $\alpha$ is that dendritic error is $0$ when the only input to a neuron stems from the given dendrite.
In other words, the dendrite predicts somatic activity perfectly, and no change in synaptic weights is required. Neuron-
and layer-specific differences in $\alpha$, as well as an analytical derivation are detailed in
\citep{sacramento2018dendritic}.

If however a current is injected into the soma (or in this case, into a different dendrite), a dendritic error arises,
and plasticity drives synaptic weights to minimize it. In addition to the learning rate $\eta$, the change in weight
$\dot{w}_{ij}$ is proportional to presynaptic activity $\phi(u_j^{som})$. Therefore, a dendritic error arising without
presynaptic contribution does not elicit a change in that particular synapse. This ensures that only synapses are
modified which recently influenced the postsynaptic neuron, providing a form of credit assignment. Updates for the
weight matrices in a hidden layer $l$ of the dendritic error model are given by:

\begin{align}
  \dot{w}_{l}^{up}   & = \eta_l^{up} \ ( \phi(u_l^{P}) - \phi(\hat{v}_l^{bas}) ) \ \phi(u_{l-1}^{P})^T\label{eq-delta_w_up}         \\
  \dot{w}_{l}^{ip}   & = \eta_l^{ip} \ ( \phi(u_l^{I}) - \phi(\hat{v}_l^{dend}) ) \ \phi(u_{l}^{P})^T\label{eq-delta_w_ip}          \\
  \dot{w}_{l}^{pi}   & = \eta_l^{pi} \ - v_l^{api} \ \phi(u_l^{I})^T\label{eq-delta_w_pi}                                           \\
  \dot{w}_{l}^{down} & = \eta_l^{down} \ ( \phi(u_l^{P}) - \phi(w_l^{down} r_{l+1}^P) )\ \phi(u_{l+1}^{P})^T\label{eq-delta_w_down}
\end{align}

each set of connections is updated with a specific learning rate $\eta$ and a specific dendritic error term. The purpose
of these particular dendritic errors will be explained in Section \ref{sec-selfpred}. Note that pyramidal-to-pyramidal
feedback weights $w_l^{down}$ are not plastic in the present simulations and are only listed for completeness. See
Section \ref{sec-feedback-plast} for a justification.

\section{The self-predicting network state}\label{sec-selfpred}

Since each interneuron receives a somatic nudging signal from its corresponding sister neuron, incoming synapses from
lateral pyramidal neurons adapt their weights to match feedforward pyramidal-to-pyramidal weights. In intuitive terms,
feedforward pyramidal-to-pyramidal weights elicit a certain activation in the subsequent layer, which is fed back into
corresponding interneurons. Hence, in the absence of other connections, nudging from sister neurons causes interneurons
to take on a proportional somatic potential. In order to minimize the dendritic error term in Equation
\ref{eq-delta_w_ip}, pyramidal-to-interneuron weight matrices at every layer must match these forward weights ($w_l^{ip}
\approx \rho w_l^{up}$) up to some scaling factor $\rho$. The exact value for $\rho$ is parameter-dependent and
immaterial for now. As long as no feedback information arrives at the pyramidal neurons, plasticity drives synaptic
weight to fulfill this constraint. Note, that this alignment of two separate sets of outgoing weights is achieved with
only local information. Therefore, this mechanism could plausibly align the weights of biological synapses that are
physically separated by long distances.

Next, consider the special case for interneuron-to-pyramidal weights in Equation \ref{eq-delta_w_pi}. In these synapses,
plasticity does not serve to reduce discrepancies between dendritic and somatic potential. The error term is instead
defined solely by the apical compartment voltage\footnote{In strict terms, it is defined by the deviation of the
dendritic potential from its specific reversal potential. Since that potential is zero throughout, $- v_l^{api}$ remains
as the error term.}. Thus, synaptic weights subject to this plasticity are altered so as to silence the apical
compartment. The apical compartments also receive feedback from superficial pyramidal neurons, whose synapses will be
considered non-plastic for now. As shown above, interneurons each learn to match their respective sister neuron
activity. Thus, silencing of apical compartments can only be achieved by mirroring the pyramidal-to-pyramidal feedback
weights ($w_l^{pi} \approx -w_l^{down}$).

When enabling plasticity in only these two synapse types, the network converges on the "\textbf{self-predicting state}"
\citep{sacramento2018dendritic}. This state is defined by a minimization of four error metrics at each hidden layer $l$:

\begin{itemize}
  \item The symmetries between feedforward ($w_l^{ip} \approx \rho w_l^{up}$) and feedback ($w_l^{pi} \approx
          -w_l^{down}$) weights. \textit{Mean squared error (MSE)} between these pairs of (scaled) matrices will be
          called \textbf{feedforward - } and \textbf{feedback weight error} respectively.
  \item Silencing of pyramidal neuron apical compartments ($v_l^{api} \approx 0$). Mean absolute apical compartment
        voltage within a layer is called the \textbf{apical error}.
  \item Equal activations in interneurons and their respective sister neurons ($\phi (u_l^I) \approx \phi (u_{l+1}^P)$).
        The mean squared error over these vectors is called the \textbf{interneuron error}.
\end{itemize}

The network does not ever reach a state in which all of these error terms are exactly zero, likely due to slight
mismatches in parameters and timing. Thus, this state is not clearly defined by absolute error thresholds, but is rather
flexible. Networks are able to learn successfully even when their weights are initialized imperfectly.


An analysis of the equations describing the network reveals that the idealized self-predicting state forms a stable
point of minimal energy. When interneuron error is zero, the nudging signal from sister neurons is predicted perfectly,
thus disabling plasticity in incoming synapses. Likewise, a silenced apical compartment will disable plasticity in all
incoming synapses from interneurons. Furthermore, the apical compartment is also the driving factor for the dendritic
error of feedforward synapses (Equation \ref{eq-delta_w_up}), since any nonzero potential leaks into the
soma\footnote{This property might actually be considered the purpose of the Urbanczik-Senn plasticity. In the original
paper, currents were injected directly into the soma to change the error term. Introducing a second dendrite which
performs that very task is far more sensible for biological neurons, and thus might also be implemented in future
iterations of the interneurons.}. As a result, in the self-predicting state all plasticiy in the network is disabled, and the
state is stable regardless of the kind of stimulus injected into the input layer. Next, notice how information flows
backwards through the network; All feedback pathways between layers ultimately pass through the apical compartments of
pyramidal neurons. Thus, successful silencing of all apical compartments implies that no information can travel
backwards between layers. As a result, the network behaves strictly like a fully connected feedforward network
consisting only of pyramidal neurons. This holds true as long as the network only receives external stimulation at the
input layer. One interpretation of this is, that the network has learned to predict its own top-down input. A failure by
interneurons to fully explain (i.e. cancel out) top-down input results in a prediction error, encoded in deviation
of apical dendrite potentials from their resting state. This prediction error in turn elicits a cascade of plasticity in
several synapses, which drives the network towards a self-predicting state that is congruent with the novel top-down
signal. The authors show analytically that this intricate mechanism can be recast as a gradient descent optimization
akin to Backprop.



\section{Training the network}

Training the network then requires only the injection of a target activation into the network's output layer alongside
with a stimulus at the input layer. Feedback connections as a result elicit a prediction error arises in the previous
layer. Synapses then drive to minimize this error by approaching a new self-predicting state in which interneurons
mirror the novel behaviour of their sisters. The new self-predicting state will minimize prediction error, while
conforming to the input-output pair injected into the layer. Note that this interaction is not exclusive to the last two
layers. Any apical errors elicit a change in somatic activity, which preceding interneurons will fail to predict. Thus,
errors are propagated backwards through arbitrarily deep networks, causing error minimization at every layer. See the
supplementary analysis of \citep{sacramento2018dendritic} for a rigorous proof that this type of network does indeed
approximate the Backpropagation algorithm.



Classical Backprop relies on a strict separation of a forward pass of some stimulus, and subsequent a backwards pass
dependent on the arising loss at the output layer. Since the present network is time-continuous, stimulus and target
activation are injected into the network simultaneously. These injections are maintained for a given presentation time
$t_{pres}$ in order to allow the network to calculate errors through its recurrent connections before slowly adapting
weights. Particluarly for deep networks, signals travelling from both the input and output layer require some time to
balance out and elicit the correct dendritic error terms. This property poses the most significant drawback of this type
of time-continuous approximation of Backprop: The network tends to overshoot activations in some neurons, which in turn
causes an imbalance between dendritic and somatic compartments. This effect causes the network to change synaptic
weights away from the desired state during the first few milliseconds of a stimulus presentation. The solution
Sacramento et al. found for this issue was to drastically reduce learning rates, while increasing stimulus presentation
time. This was sufficient to prove that plasticity in this kind of network is able to perform error propagation, but
still has some issues. Most notably, training is highly inefficient and computationally intensive. A closer
investigation of this and an alternative solution will be presented in Section \ref{sec-latent-eq}.



\section{The NEST simulator}

One of the key research questions motivating this thesis is whether the network would be able to learn successfully when
employing spike-based communication instead of the rate neurons for which it was developed. As a framework for the
spike-based implementation two options were considered: The first one was to use the existing implementation of the
network which employs the Python frameworks \texttt{PyTorch} and \texttt{NumPy}, and expand it to employ spiking
neurons. PyTorch does in principle support spiking communication between layers, but is streamlined for implementing
less recurrent and less complex network and neuron models. Another concern is efficiency; PyTorch is very well optimized
for computing matrix operations on dedicated hardware. This makes it a good choice for simulating large networks of rate
neurons, which transmit all of their activations between layers at every simulation step. Spiking communication between
leaky neurons is almost antithetical to this design philosophy and thus was expected to perform comparatively poorly
when using this backend.

The second option was to use the NEST simulator (\url{https://nest-simulator.readthedocs.io}, \cite{Gewaltig2007}), which was developed
with highly parallel simulations of large spiking neural networks in mind. It is written in C++ and uses the
\textit{Message Passing Interface} (\url{https://www.mpi-forum.org/}) to efficiently communicate events between
both threads and compute nodes. One design pillar of the simulator, which is particularly relevant for this project, is
the event-based communication scheme that underpins all simulated nodes. It ensures that communication bandwidth at is
only used by the subset of nodes which transmit events at that time step, which is particularly efficient for spiking
communication. Another important advantage of the NEST simulator is, that an event-based implementation of the
Urbanczik-Senn plasticity alongside a corresponding neuron model had already been developed for it. Therefore, it was
decided to implement the spiking neuron model in the NEST simulator.

The simulator has one particular limitation which needs to be considered. As communication between physically separate
compute nodes takes time, Events\footnote{An Event in NEST is an abstract C++ Class that is created by neurons, and
transmitted across threads and compute nodes by the Simulator. A Multitude of Event types are provided (i.e.\
\texttt{SpikeEvent, CurrentEvent, RateEvent}), each able to carry specific types of payload and being processed
differently by postsynaptic neurons.} in NEST can not be handled in the same simulation step in which they were sent.
Thus, NEST enforces a synaptic transmission delay of at least one simulation step for all connections. This property is
integral to other parallel simulation backends \citep{Hines1997} as well as neuromorphic hardware
\citep{davies2018loihi}. It may not even considered a limitation by some, as synaptic transmission within biological
neurons is never instantaneous either \citep{kandel2021principles}. Yet particularly with regard to the relaxation
period (cf. Section \ref{sec-latent-eq}), it can be expected to affect performance.


\section{Transitioning to spiking communication}

The spiking neuron models rely heavily on the NEST implementation from \citep{Stapmanns2021}, which was used show that
spiking neurons are able to perform learning tasks that were designed for the rate neurons described in
\citep{urbanczik2014learning}. The existing model is an exact replication of the Urbanczik-Senn neuron in terms of
membrane dynamics. The critical update of the NEST variant is that instead of transmitting their hypothetical rate $r =
\phi(u)$ at every time step, these neurons emit spikes in a similar way to stochastic binary neurons
\citep{Ginzburg1994}. The number of spikes to be generated during a simulation step $n$ is determined by drawing from a
Poisson distribution, which takes $r$ as a parameter:

\begin{align}
  P\{\textit{n} \ \text{spikes during} \ \Delta t\} & = e^{-r \Delta t} \frac{(r \ \Delta t) ^ n}{n!}\label{eq-pr-n-spikes} \\
  \langle \textit{n} \rangle                        & = r \ \Delta t \label{eq-n-spikes}
\end{align}

where $\Delta t$ denotes the integration time step of the simulator, which will be assumed to be $0.1 ms$ from here on
out.  $\langle \textit{n} \rangle$ denotes the expected number of spikes to be emitted in a simulation step. Note that
this mechanism makes the assumption that more than one spike can occur per simulation step. As the high spike
frequencies resulting from this could not occur in biological neurons, the model is also capable of simulating a
refractory period after every evoked spiked.

In order to implement the plasticity rule for spiking neurons, dendritic compartments need to be modeled with leaky
dynamics. These dynamics are fundamentally the same as those described for the somatic compartment. Thus, the basal
compartment of a pyramidal neuron $j$ evolves according to:

\begin{align}
  C_m^{bas} \dot{v}_j^{bas} & = -g_l^{bas} \  v_j^{bas} + \sum_{i \in I} W_{ji} s_i(t)     \label{eq-spiking-basal-compartment}
\end{align}

with presynaptic neurons $I$, and membrane capacitance $C_m^{bas}$ and leakage conductance $g_l^{bas}$ being specific to
the basal dendrite. Note that these equations are calculated individually for each neuron and do not employ the matrix
computations previously described for layers of rate neurons. Pyramidal apical and interneuron dendritic compartments
evolve by the same principle and with largely the same parameters. The choice of dendritic leakage conductance
$g_l^{dend}=\Delta t=0.1$ is motivated in Section \ref{sec-gl-dend}.


\section{Event-based Urbanczik-Senn plasticity}\label{sec-event-urb}

One major challenge in implementing this architecture with spiking neurons is the Urbanczik-Senn plasticity introduced
in Section \ref{sec-urb-senn-plast}.  Fortunately, this problem has already been solved in NEST for two-compartment
neurons \citep{Stapmanns2021}. This Section will discuss the algorithm and its implementation.


Since NEST is an event-based simulator, most of the plasticity mechanisms developed for it compute weight changes at the
location (i.e. thread and compute node) of the postsynaptic neuron whenever an Event is received. This has several
advantages: It allows the thread that created the Event to continue processing neuron updates instead of having to
synchronize with all threads that manage recipient neurons.  More importantly, this feature mirrors the local properties
of most biologically plausible synaptic plasticity models, as these are often considered to be primarily dependent on
factors that are local to the synapse \citep{magee2020synaptic}. For a spiking implementation of the Urbanczik-Senn
plasticity, dendritic errors at every time step are required instead of just a scalar trace at the time of a spike, as
would be the case for STDP. Thus, a mechanism for managing these errors was required, for which two basic possibilities
were considered:

In a \textbf{Time-driven scheme}, dendritic errors are made available to synapses at every timestep, and weight changes
are applied instantaneously. This approach is in principle an adaptation of the original computations for spiketrains.
Its main drawback is that calls to the synaptic update function are as frequent as neuron updates - for all synapses.
Particularly for large numbers of incoming synapses, as is common for simulations of cortical pyramidal neurons
\citep{potjans2014cell,vezoli2004quantitative}, this requires arguably too many function calls per time step. Therefore,
this approach proved costly in terms of computational resources.

An \textbf{Event-driven scheme} on the other hand, updates synaptic weights only when a spike is sent through the
synapse. A history of the dendritic error is stored at the postsynaptic neuron, which is read by each synapse when a
spike is transmitted. As the history of dendritic error applies equally to all incoming synapses, it only needs to be
recorded once at the neuron. Alongside each entry in the history, a counter is stored and incremented whenever a synapse
has read the history at that time step. Once all synapses have read out an entry, it is deleted. Thus, the history
dynamically grows and shrinks during simulation and is only ever as long as the largest inter-spike interval (ISI) of
all presynaptic neurons. This approach proves to be more efficient in terms of computation time, since fewer calls to
the update function are required per synapse. It does come at the cost of memory consumption, as the history can grow
particularly large for simulations with low in-degrees or large ISI\footnote{It should also be noted that in this
approach requires redundant integration of the history by every synapse. Stapmanns et al. propose a third solution, in
which this integration is performed once whenever a spike is transmitted through any incoming connection, with the
resulting weight change being applied to all synapses immediately. This approach proved to be even more efficient for
some network configurations, but is incompatible with simulations where incoming synapses have heterogeneous synaptic
delays due to the way that these delays are processed by the NEST simulator. See Section 3.1.3 in \citep{Stapmanns2021}
for a detailed explanation.}. During testing, the Event-based schemed proved substantially more efficient for many
network types. This did however introduce the challenge of retroactively computing weight changes  upon the arrival of a
spike.


\subsection{Integrating weight changes}


Stapmanns et al. describe the Urbanczik-Senn plasticity rule based on the general equation for weight changes, while
omitting obsolete parameters:

\begin{align}
  \dot{w}_{ij}(t) & = F(s_j^\ast (t), V_i^\ast (t)) \label{eq-delta-w-spiking}
\end{align}

where the change in weight $\dot{w}_{ij}$ of a synapse from neuron $j$ to neuron $i$ at time $t$ is given by a function
$F$ that depends on the postsynaptic membrane potential $V_i^\ast$ and the presynaptic spiketrain $s_j^\ast$. The $\ast$
operator denotes a causal function, indicating that a value $V_i^\ast(t)$ potentially depends on all previous values of
$V_i(t' < t)$. One can formally integrate Equation \ref{eq-delta-w-spiking} in order to obtain the weight change between
two arbitrary time points $t$ and $T$:

\begin{align}
  \Delta w_{ij}(t,T) & = \int_t^T dt' F[s_j^\ast, V_i^\ast](t') \label{eq-delta-w-t-T}
\end{align}

this integral forms the basis of computing the change in weight between two arriving spikes. Thus, at the
implementational level, $t$ is usually the time of the last spike that traversed the synapse, and $T$ is the current
\texttt{biological\_time}\footnote{This term is adopted from the NEST convention, where it describes the time in $ms$
which the simulator has computed. In other words, it is the number of simulation steps times $\Delta t$, not to be
confused with a simulation's hardware-dependent runtime (sometimes also called \textit{wall clock time}
\citep{albada2018performance}). }. For spiking neurons, it is necessary to approximate the presynaptic rate
($r_j=\phi(u_j)$). For this, a well established solution is to transform the spiketrain $s_j$ into a decaying trace
using an exponential filter kernel $\kappa$:

\begin{align}
  \kappa(t)     & = H(t) \frac{1}{t}e^{\frac{-t}{\tau_{\kappa}}}                        \\
  H(t)          & =
  \begin{cases}
    1 & \text{if $t > 0$}    \\
    0 & \text{if $t \leq 0$} \\
  \end{cases}                                                              \\
  (f \ast g)(t) & = \int_{- \infty }^{\infty} f(t') g(t-t') d t' \label{eq-convolution} \\
  s_j^\ast      & = \kappa_s \ast s_j. \label{eq-spike-trace}
\end{align}

with filter time constant $\tau_\kappa$. The trace is computed by convolving (Equation \ref{eq-convolution}) the
spiketrain with the exponential filter kernel $\kappa$. The filter uses the Heaviside step function $H(t)$, and is
therefore only supported on positive values of $t$ (also called a one-sided exponential decay kernel). This property is
important, as integration limits of the convolution can be truncated when $f$ and $g$ are both only supported on
$[0,\infty)$:

\begin{align}
  (f \ast g)(t) & = \int_{0}^{t} f(t') g(t-t') d t'
\end{align}

since spikes naturally only occur for $t>0$, this simplified integral allows for a much more efficient computation of
the convolution. The Function $F$ on the right-hand side of Equation \ref{eq-delta-w-spiking} can therefore be rewriten
as:

\begin{align}
  F[s_j^\ast, V_i^\ast] & = \eta \kappa \ast (V_i^\ast s_j^\ast)        \\
  V_i^\ast              & = (\phi(u_i^{som}) - \phi(\hat{v}_i^{dend}) )
\end{align}

with learning rate $\eta$. $V_i^\ast$ then is the dendritic error of the dendrite that the synapse between $j$ and $i$
is located at\footnote{The dendritic error here is defined as the difference between two hypothetical rates based on the
arbitrary function $\phi$. The original implementation uses the difference between the true postsynaptic spiketrain and
this dendritic prediction ($V_i^\ast = (s_i - \phi(\hat{v}_i^{dend}) )$). Furthermore, Stapmanns et al. show that
generating a spiketrain from the dendritic potential ($V_i^\ast = (s_i - s_i^{dend})$) also results in successful
learning, although at the cost of additional training time. The rate-based variant was chosen in order to not hinder
learning performance any more than necessary.}. Writing out the convolutions in Equation \ref{eq-delta-w-t-T}
explicitly:

\begin{align}
  \Delta w_{ij}(t,T) & = \int_t^T dt' F[s_j^\ast, V_i^\ast](t')                                                                           \\
                     & =  \int_t^T dt' \  \eta\int_0^{t'} dt'' \ \kappa(t'-t'') V_i^\ast (t'') s_j^\ast (t'') \label{eq-delta-w-t-T-long}
\end{align}

computing this Equation directly is somewhat inefficient due to the nested integrals. Yet, the authors show that it is
possible to break up the integrals into two simpler computations and rewrite the weight change as:


\begin{align}
  \Delta W_{ij}(t, T) & = \eta \left[ I_1 (t, T) - I_2(t,T) + I_2(0,t)\left( 1- e^{-\frac{T-t}{\tau_\kappa}} \right) \right]\label{eq-proof-start} \\
  I_1(a, b)           & = -\int_{a}^{b} dt \ V_i^\ast (t) s_j^\ast (t)                                                                             \\
  I_2(a, b)           & = -\int_{a}^{b} dt \ e^{-\frac{b-t}{\tau_\kappa}} V_i^\ast (t) s_j^\ast (t)\label{eq-proof-end}                            \\
\end{align}

see Section 5.1 in \citep{Stapmanns2021} for a rigorous proof that this is in fact the desired integral. The resulting
equations allow for a rather efficient computation of weight changes compared to the complex integral described in
Equation \ref{eq-delta-w-t-T-long}. This integration is performed whenever a spike traverses a synapse. It generalizes
to all special cases in Equations \ref{eq-delta_w_up}-\ref{eq-delta_w_down}, as long as the appropriate dendritic error
is stored by the postsynaptic neuron.

\section{Latent Equilibrium}\label{sec-latent-eq}

The most significant drawback of the dendritic error model is the previously mentioned requirement for long stimulus
presentation times and appropriately low learning rates. This makes the network prohibitively inefficient for the large
networks required for complex learning tasks. Sacramento et al. developed a steady-state approximation of their network
which models the state of the network after it has fully relaxed in response to a stimulus-target pair. It does not
suffer from these issues and shows that their model can in principle solve more demanding learning tasks such as MNIST.
Yet, these types of approximation are much further detached from biological neurons than the original model and thus do
not lend themselves well to an investigation of biological plausibility \citep{Gerstner2009}. Furthermore, the
approximation is unsuitable for and investigation of spike-based communication, since the steady state of both spiking
and rate-based networks ideally would be the same. Thus, neither the fully modeled neuron dynamics nor the steady-state
approximation are suited for complex learning tasks in the context of this thesis. A substantial improvement to rate
neurons which promises to solve this dilemma was developed by \citep{Haider2021}, and will be discussed here.

The requirement for long stimulus presentation times of the dendritic error network is caused by the slow development of
leaky neuron dynamics, and is therefore not unique to this model. The time until a network of leaky neurons has reached
its steady state after a change in input is called the \textit{relaxation period} following \citep{Haider2021}. Given a
membrane time constant $\tau_m$, a feedforward network with $N$ layers of leaky neurons thus has a relaxation time
constant of $N \tau_m$. Yet, in the present model, a target activation simultaneously injected into the output neurons
slowly propagates backwards through the highly recurrent network. Neurons at early layers require all subsequent layers
to be fully relaxed in order to correctly compute their dendritic error terms, effectively being dependent on two
network passes. Haider et al. state that this kind of network therefore requires $2N\tau_m$ to relax in response to a
given input-output pairing. This prediction proved to be slightly optimistic in experiments, as shown in Fig.
\ref{fig-error-comp-le}.


Slow network relaxation is a major issue, as it implies that plasticity during the first few miliseconds of a stimulus
presentation is driven by faulty error terms. The network then needs to undo the weight changes made during the
relaxation period in the later phase of a stimulus presentation, in order to make tangible progress on the learning
task. Haider et al. call this issue the "relaxation problem" and suggest that it might be inherent to most established
attempts at biologically plausible Backpropagation algorithms
\citep{Whittington2017,guerguiev2017towards,sacramento2018dendritic,millidge2020activation}.



The choice to simply increase presentation time to compensate for the relaxation period is therefore somewhat
problematic. It implicitly tolerates adverse synaptic plasticity in all synapses, which are counteracted by enforcing
the desired plasticity for a longer time. Physiological changes that are meant to immediately be undone are of course an
inefficient use of a brain's resources, which can be considered highly untypical for a biological system. One possible
solution to this is to decrease synaptic time constants and remove the temporal filtering of stimulus injections. Yet
this does not solve the fundamental issue that during a substantial portion of stimulus presentations, the network is
driven by erroneous plasticity. Removing temporal filtering does decrease the length of the relaxation period, but
causes a drastic increase in dendritic error values during that period. Therefore, while improving response time, this
change effectively impedes learning further. Another possible solution is to disable plasticity for the first few milliseconds
of stimulus presentation. After the network has relaxed, the plasticity rules produce useful weight changes and learning
rates can consequently be safely increased. Yet a mechanism by which neurons could implement this style of phased
plasticity is yet to be found, making this approach questionable in terms of biological plausibility. Furthermore, it
introduces the demand for external control to the network, a trait that is considered highly undesirable for
approximations of Backprop \citep{whittington2019theories}. Ideally, the relaxation period would be skipped or
shortened in order to reduce the erroneous plasticity. This would allow for a loosening of the constraints put on
presentation time and learning rates, thus increasing computational efficiency.



The approach proposed by Haider et al. is to change the parameter of the activation function $\phi$, a mechanism called
\textit{Latent Equilibrium} (LE). Neurons in the original dendritic error network transmit a function of their somatic
potential $u_i$, which is updated through Euler integration at every simulation step (Equation \ref{eq-r-t-sacramento}).
In contrast, neurons using Latent Equilibrium (henceforth called \textit{LE neurons}) transmit a function of what the
somatic potential is expected to be in the future. To calculate this expected future somatic potential $\breve{u}$, the
integration is simply performed with a larger Euler step:

\begin{align}
  u_i(t+ \Delta t)          & = u_i(t) + \dot{u}_i(t) \ \Delta t \label{eq-r-t-sacramento} \\
  \breve{u}_i(t + \Delta t) & = u_i(t) + \dot{u}_i(t) \ \tau_{eff} \label{eq-r-t-haider}
\end{align}

instead of broadcasting their rate based on the current somatic potential ($r_i(t) = \phi(u_i(t))$), LE neurons transmit
their predicted future activation, denoted as $\breve{r}_i(t) = \phi(\breve{u}_i(t))$. The degree to wich LE neurons
look ahead is determined by the \textit{effective membrane time constant} $\tau_{eff} = \frac{C_m}{g_l + g^{bas} +
g^{api}}$. This time constant takes into account the conductance with which dendritic compartments leak into the soma,
which is a key driving factor for the speed at which the network relaxes. Any computations that employ or relate to this
prediction of future network states will henceforth be referred to as \textit{prospective} and denoted with a breve
$\breve{}$. Note, that the breve operator mathematically is the exact inverse of an exponential low-pass filter.


\begin{figure}[h!]
  \centering
  \includegraphics[width=0.9\textwidth]{fig_le_response}
  \caption[Signal transmission of LE neurons]{Signal transmission of LE neurons. Shown is the influence of an input
    neuron $i$ on a hidden layer pyramidal neuron $j$. Activations for the original Sacramento model (blue) and
    prospective activation using LE (orange) are compared. \textbf{A:} Current injected into the input neuron. Membrane
    potential evolves to match this at the same speed in both variants (not shown). \textbf{B:} Activation of the input
    neuron using instantaneous- (blue), and prospective activation (orange). Note how strongly prospective activation
    reacts to changes in somatic voltage, leading to 'bursts' in neuron output. After the input neuron has reached its
    relaxed state ($\dot{u}_i = 0$), both mechanisms evoke the same activation. \textbf{C:} Somatic potential $u_j$ of
    the pyramidal neuron responding to signals sent from the input neuron (color scheme as in B).}
  \label{fig-comparison-le}
\end{figure}

When employing the default parametrization provided by Haider et al., $\tau_{eff}$ is slightly
lower than reported pyramidal neuron time constants \citep{McCormick1985} at approximately $5.26ms$. When presynaptic
neurons employ prospective dynamics, postsynaptic neurons approach their steady state much more quickly, as depicted in
Fig. \ref{fig-comparison-le}. In intuitive terms, prospective activation is more strongly dependent on the derivative
membrane potential compared to the instantaneous activation. This results in drastic changes in activation in response
to changes in the somatic membrane potential. While this can lead to an overshoot of postsynaptic activity, under
careful parametrization it strongly decreases response time.


\begin{figure}[h!]
  \centering
  \includegraphics[width=0.9\textwidth]{fig_le_dendritic_errors}
  \caption[Effects of LE dynamics on dendritic error]{Effects of LE dynamics on the dendritic error terms from Equations
    \ref{eq-delta_w_up}-\ref{eq-delta_w_down}. Depicted are error terms for individual spiking neurons in a network with
    one hidden layer (N=3). The network was fully trained on the Bars dataset (cf. Section \ref{sec-le-tpres}), so
    errors are expected to converge close to zero. In the original dendritic error network (orange), dendritic errors
    exhibit longer and more intense deviations, while errors in an identical LE network (blue) relax much sooner.
    \textbf{A:} Basal dendritic error for a pyramidal neuron at the output layer. \textbf{B:} Dendritic error for a
    hidden layer interneuron. \textbf{C:} Proximal apical error for a hidden layer pyramidal neuron. \textbf{D:} Distal
    apical error for the same pyramidal neuron. Note that this error term does not converge to zero for either network,
    an issue that will be discussed in Section \ref{sec-feedback-plast}.}
  \label{fig-error-comp-le}
\end{figure}


When employing prospective dynamics in the dendritic error networks, local error terms of pyramidal- and interneurons
relax much faster, as shown in Fig. \ref{fig-error-comp-le}. These simulations highlight the superiority of LE for
learning in this network, as the relaxation period is almost instantaneous. In contrast, the error terms in the original
dendritic error network drive random synaptic plasticity even when the network is fully trained on a given dataset and
is able to make accurate predictions. Thus, both the issue of erroneous weight changes, as well as concerns over
response time and learning speed can be solved by LE. The authors furthermore show, that learning with this mechanism is
indifferent to presentation times or effective time constants in their rate neuron model.

In addition to using the prospective somatic potential for the neuronal transfer function, it is also used in the
plasticity rule of LE neurons. The Urbanczik-Senn plasticity is updated to compute dendritic error from
prospective somatic activations and a non-prospective dendritic potential $\dot{w}_{ij}= \eta \ (
\phi(\breve{u}_i^{som}) - \phi(\hat{v}_i^{bas}) ) \ \phi(\breve{u}_j^{som})^T$. Much like for the transfer function,
this change serves to increase the responsiveness of the network to input changes.

\section{Implementational details}

Building on the neuron and plasticity model from \citep{Stapmanns2021}, a replicate model of the pyramidal neuron with
spike-based communication was developed in NEST. The existing neuron model was expanded to three compartments, and
storage and readout of dendritic errors were updated  to allow for compartment-specific plasticity rules. Interneurons
were chosen to be modeled as pyramidal neurons with slightly updated parameters and apical conductance $g^{api}=0$.
Since membrane dynamics of both neurons follow the same principles and additional compartments have minor impact on
performance, this was deemed sufficient.

After facing some setbacks when attempting to train the first spiking variant of the network, the decision was made to
also implement a rate-based variant of the neuron in NEST.  While the additional effort required for another
implementation might be questionable, this model turned out to be indispensible. It enabled the identification of both
errors in the model, as well as training mechanisms and parameters that required changes to enable spike-compatible
learning. The rate version in NEST additionally served to distinguish discrepancies that are due to the novel simulation
backend from those that were introduced by the spike-based communication scheme (cf. Section \ref{sec-le-tpres}).

Following NEST convention, the spiking and rate-based neuron models were named \texttt{pp\_\allowbreak cond\_\allowbreak
  exp\_\allowbreak mc\_\allowbreak pyr}\footnote{Despite being somewhat cryptic, the name does actually make sense, as
  it describes some key features of the model: It is a \textbf{point process} for \textbf{cond}uctance based synapses
  and has an \textbf{exp}onentially decaying membrane in \textbf{multiple compartments}.} and \texttt{rate\_\allowbreak
  neuron\_\allowbreak pyr} respectively. Furthermore, the \texttt{pyr\_\allowbreak synapse} class was defined for spike
  events, and implements the event-based variant of the Urbanczik-Senn plasticity described in Section
  \ref{sec-event-urb}. The \texttt{pyr\_\allowbreak synapse\_\allowbreak rate} model on the other hand transmits rate
  events and updates its weight instantaneously according to the original plasticity rule.

Simulations were managed using the python API \texttt{PyNEST} \citep{Eppler2009}. An advantage of using this language
is, that the LE network  is also implemented in python. Thus, by including a slightly modified version of that code in
my project, it was possible to unify all three variants in a single network class and accompanying interface. This
allowed for exact alignment of network stimulation and readout and enabled in-depth comparative analyses. In some of the
upcoming sections, three variants of the same network architecture will therefore be compared; the modified python
implementation from \citep{Haider2021} is termed \texttt{NumPy} based on the framework that is used to compute the
relevant matrix multiplications. The two NEST variants will be referred to as
\textit{NEST spiking} and \textit{NEST rate}.

\subsection{Model adaptations}

A major issue of the spiking network is the fact that under the default parametrization, spikes are too infrequent for
the network to accurately compute the dendritic error terms. Initial experiments showed that the network is rather
sensitive to changes in parametrization, which meant that it was desirable to change as few existing parameters as
possible. Therefore, a novel parameter $\psi$ was introduced to increase spike frequency independently from the
network's other parameters. In a spiking neuron $i$, the probability of eliciting a spike is linearly increased by this
factor ($r_i = \psi \phi(u_i)$). Likewise, all synaptic weights $W$ in a spiking network are attenuated by the same
factor ($W \leftarrow \frac{W}{\psi}$). These changes cancel each other out, and an increased value for $\psi$ elicits
no change in absolute compartment voltages of a network. Instead, it serves to stabilize these voltages over time, which
drastically improves learning performance. One mechanism in which this parameter also needs to be considered is the
plasticity rule. Weight changes are affected by $\psi$ multiple times, which can be observed when explicity pulling it
out of the activation function. As an example, take feedforward weights at layer $l$:

\begin{align*}
  \dot{w}_{l}^{up}   & = \eta_l^{up} \ ( \phi(u_l^{P}) - \phi(\hat{v}_l^{bas}) ) \ \phi(u_{l-1}^{P})^T\\
  \dot{w}_{l}^{up}   & = \eta_l^{up} \ ( \psi\phi(u_l^{P}) - \psi\phi(\hat{v}_l^{bas}) ) \ \psi\phi(u_{l-1}^{P})^T\\
  \dot{w}_{l}^{up}   & = \psi^2 \ \eta_l^{up} \ (\phi(u_l^{P}) - \phi(\hat{v}_l^{bas}) ) \ \phi(u_{l-1}^{P})^T
\end{align*}

Additionally, the frequency of weight changes in the spiking implementation is determined by the presynaptic spike rate,
thus weight changes are increased multiplicatively one more time. Therefore, learning rates in the spiking variant are
attenuated by $\eta \leftarrow \frac{\eta}{\psi^3}$. The exception to this are the weights from interneurons to
pyramidal neurons, as these do not depend on dendritic predictions, but on absolute dendritic voltage. Hence, in this
case $\eta^{pi} \leftarrow\frac{\eta^{pi}}{\psi^2}$. This update is performed by the simulation environment, and must
not be considered when setting up a simulation.


On close investigation of the spiking neuron model, one can observe that for $\psi \rightarrow \infty$, it approximates
the rate-based implementation exactly at the steady state. Unsurprisingly therefore, increasing $\psi$ caused the
spiking network to learn successfully with fewer samples and to a lower test loss. Yet, the argument against increasing
$\psi$ is twofold: Initial experiments showed that only for $\psi < 0.1$ did pyramidal and interneurons exhibit spike
frequencies in biologically plausible range of less than $55Hz$ \citep{Kawaguchi2001,Eyal2018}. Additionally, each
transmitted \texttt{SpikeEvent} is computationally costly, which increases training time (cf. Fig.
\ref{fig-benchmark-threads-psi}) and therefore further makes high spike frequencies undesirable. During initial tests,
$\psi = 100$ proved useful and will be assumed the default from here on out. With these adaptations, the network was
able to perform supervised learning with spiking neurons, as will be discussed in the upcoming sections.

\section{Error metrics and nomenclature}

In this thesis, the word 'error' is used frequently, which might understandably lead to confusion. While stylistically
questionable, this choice was made deliberately to conform to the main underlying works
\citep{urbanczik2014learning,sacramento2018dendritic,whittington2019theories,Haider2021}. This section will provide a
brief disambiguation. Firstly, there are four error metrics describing the network's deviation from the self-predicting
state: \textit{Feedforward weight error (FF error), Feedback weight error (FB error), apical error and interneuron
error}. These were introduced in Section \ref{sec-selfpred}\footnote{Observation of the network dynamics reveals that
pairs of them are closely related: FF error drives interneuron error, and FB error drives apical error as soon as
interneuron error is minimal. An analytical upgrade to this model might include a way for unifying these pairs of
metrics.}. Furthermore, three terms require elaboration:\newline

\textbf{Dendritic error}: Any value which drives weigh changes in the plasticity rules. Classically, this refers to a
failure of a dendrite to predict somatic activity \citep{urbanczik2014learning}. In this context, due to the changes to
the plasticity rule, it may also refer to absolute voltage of pyramidal neuron apical compartments (i.e. apical error).
\newline

\textbf{Train error}: Failure rate of a network to correctly classify inputs during testing. In the upcoming
simulations, all targets are encoded with one-hot vectors. Thus, accuracy is defined as:
\begin{align*}
  accuracy & = \frac{1}{N} \sum_{i=1}^N \  \delta \left(argmax(y^{target}_i),\ argmax(y^{pred}_i) \right)
\end{align*}
for a test run over $N$ samples, with $\delta$ being the Kronecker delta function. Train error is defined as inverse
accuracy.\newline

\textbf{Loss}: Unless specified otherwise, train- and test loss are are computed through MSE between predicted and
target output:
\begin{align*}
  MSE & = \frac{1}{M} \sum_{i=1}^M \left( y^{target}_i-y^{pred}_i \right)^2
\end{align*}
with $M$ neurons in the output layer, which is again averaged over $N$ test samples. Due to the network's relaxation
period, $y^{pred}$ can not be accurately computed instantaneously\footnote{Sacramento et al. actually do exactly this.
They compute $y^{pred}$ without neuron dynamics, only from the input, activation function $\phi$, and feedforward
weights. This approach makes the assumption that the network is permanently in a perfect self-predicting state, in which
lateral and feedback weights have no impact on pyramidal neuron activity. Particularly for the spiking variant, this
assumption was shown to be erroneous, leading to artificially inflated performance. Hence, all tests are performed by
fully simulating networks with disabled plasticity.}. Instead, the network needs to be presented with the stimulus for a
given time $t_{pres}$. Particularly for the SNN, as well as networks injected with noise, output layer membranes
fluctuate strongly. therefore, $y^{pred}$ is an average over recorded somatic potentials for each output neuron. This
recording typically starts after $\sim 70\%$ of $t_{pres}$ has passed.